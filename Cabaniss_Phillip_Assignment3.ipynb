{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,667,594\n",
      "Trainable params: 1,667,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 94s 2ms/step - loss: 1.7256 - accuracy: 0.3771 - val_loss: 1.4169 - val_accuracy: 0.4882\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 91s 2ms/step - loss: 1.3112 - accuracy: 0.5332 - val_loss: 1.2784 - val_accuracy: 0.5592\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 92s 2ms/step - loss: 1.1363 - accuracy: 0.5983 - val_loss: 1.0812 - val_accuracy: 0.6147\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 99s 2ms/step - loss: 1.0334 - accuracy: 0.6375 - val_loss: 1.0595 - val_accuracy: 0.6221\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 91s 2ms/step - loss: 0.9526 - accuracy: 0.6675 - val_loss: 0.9142 - val_accuracy: 0.6826\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 99s 2ms/step - loss: 0.8827 - accuracy: 0.6946 - val_loss: 0.8209 - val_accuracy: 0.7161\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 106s 3ms/step - loss: 0.8226 - accuracy: 0.7125 - val_loss: 0.8206 - val_accuracy: 0.7190\n",
      "Epoch 8/20\n",
      "13696/40000 [=========>....................] - ETA: 59s - loss: 0.7703 - accuracy: 0.7341"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10 \n",
    "from keras.utils import np_utils \n",
    "from keras.models import Sequential \n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D \n",
    "from keras.optimizers import SGD, Adam, RMSprop \n",
    "import matplotlib.pyplot as plt \n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "\n",
    "\n",
    "# CIFAR_10 is a set of 60K images 32x32 pixels on Flatten 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "IMG_ROWS = 32 \n",
    "IMG_COLS = 32 \n",
    "\n",
    "#constant \n",
    "BATCH_SIZE = 128 \n",
    "NB_EPOCH = 20 \n",
    "NB_CLASSES = 10 \n",
    "VERBOSE = 1 \n",
    "VALIDATION_SPLIT = 0.2 \n",
    "OPTIM = RMSprop() \n",
    "\n",
    "#load dataset \n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data() \n",
    "print('X_train shape:', X_train.shape) \n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert to categorical \n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES) \n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES) \n",
    "\n",
    "#float and normalization \n",
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32') \n",
    "X_train /= 255 \n",
    "X_test /= 255\n",
    "\n",
    "# network \n",
    "model = Sequential() \n",
    "model.add(Conv2D(32, (3, 3), padding='same', \n",
    "                 input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS))) \n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same')) \n",
    "model.add(Activation('relu')) \n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(512)) \n",
    "model.add(Activation('relu')) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(NB_CLASSES)) \n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "# train \n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM, metrics=['accuracy']) \n",
    "model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=NB_EPOCH, \n",
    "          validation_split=VALIDATION_SPLIT, verbose=VERBOSE) \n",
    "score = model.evaluate(X_test, Y_test, \n",
    "                       batch_size=BATCH_SIZE, verbose=VERBOSE) \n",
    "print(\"Test score:\", score[0]) \n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#save model \n",
    "model_json = model.to_json() \n",
    "open('cifar10_architecture.json', 'w').write(model_json) \n",
    "#And the weights learned by our deep network on the training set\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "NUM_TO_AUGMENT = 5\n",
    "\n",
    "#load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# augmenting\n",
    "print(\"Augmenting training set images...\")\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "rotation_range=40,\n",
    "width_shift_range=0.2,\n",
    "height_shift_range=0.2,\n",
    "zoom_range=0.2,\n",
    "horizontal_flip=True,\n",
    "fill_mode='nearest')\n",
    "\n",
    "xtas, ytas = [], []\n",
    "for i in range(X_train.shape[0]):\n",
    "    num_aug = 0\n",
    "x = X_train[i] # (3, 32, 32)\n",
    "x = x.reshape((1,) + x.shape) # (1, 3, 32, 32)\n",
    "for x_aug in datagen.flow(x, batch_size=1, \n",
    "save_to_dir='preview', save_prefix='cifar', save_format='jpeg'):\n",
    "    if num_aug >= NUM_TO_AUGMENT:\n",
    "        break\n",
    "xtas.append(x_aug[0])\n",
    "num_aug += 1\n",
    "\n",
    "\n",
    "#fit the datagen\n",
    "datagen.fit(X_train)\n",
    "\n",
    "#train\n",
    "history = model.fit_generator(\n",
    "    datagen.flow(\n",
    "        X_train, \n",
    "        Y_train, \n",
    "        batch_size=BATCH_SIZE),\n",
    "    samples_per_epoch=X_train.shape[0],\n",
    "    epochs=NB_EPOCH,\n",
    "    verbose=VERBOSE)\n",
    "\n",
    "score = model.evaluate(\n",
    "    X_test,\n",
    "    Y_test, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    verbose=VERBOSE)\n",
    "print(\"Test score: \", score[0])\n",
    "print(\"Test accuracy: \", score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm can not only lead to facial recognition software, but it is not accurate in the slightest. Yes its accuracy gets stronger the more augment the network and make it stronger. However, ethically, these images would need to be diverse and varying to ensure that biases are not programmed in. If for instance, there was a facial recognition program used by the police, and biases were programmed in to monitor people of color more than white people, this could lead to potential issues. Furthermore, would be the storage of all of this data. Who would have access? What rights do we have to this information? How will it be used? All of these questions raise the ethical concerns that are apparent in software like this. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
